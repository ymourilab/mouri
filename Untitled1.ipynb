{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ymourilab/mouri/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx0XjR2V5oQa",
        "colab_type": "code",
        "outputId": "b22bb426-a6fa-4c0e-8954-fb0f39e64c61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "!git clone https://github.com/fbcotter/pytorch_wavelets\n",
        "!pip install ./pytorch_wavelets/."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch_wavelets'...\n",
            "remote: Enumerating objects: 125, done.\u001b[K\n",
            "remote: Counting objects: 100% (125/125), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 836 (delta 75), reused 93 (delta 56), pack-reused 711\n",
            "Receiving objects: 100% (836/836), 6.70 MiB | 8.42 MiB/s, done.\n",
            "Resolving deltas: 100% (566/566), done.\n",
            "Processing ./pytorch_wavelets\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-wavelets==1.1.0) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pytorch-wavelets==1.1.0) (1.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pytorch-wavelets==1.1.0) (1.3.1)\n",
            "Building wheels for collected packages: pytorch-wavelets\n",
            "  Building wheel for pytorch-wavelets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-wavelets: filename=pytorch_wavelets-1.1.0-cp36-none-any.whl size=46100 sha256=42cac5145a4c87632129d8a2a4ef616479e7bbbefd9a302ae81f2998a7817b2d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q298ocyc/wheels/82/e1/5b/16a4e6ccfc0bb2ce14bd2796adb13e6e9b718cb7d2e1ae3643\n",
            "Successfully built pytorch-wavelets\n",
            "Installing collected packages: pytorch-wavelets\n",
            "Successfully installed pytorch-wavelets-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raA6CcvL519a",
        "colab_type": "code",
        "outputId": "2b32e051-1c92-492a-b576-d5fe99dcdad4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!git clone https://github.com/zh217/torch-dct\n",
        "!pip install ./torch-dct/."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'torch-dct'...\n",
            "remote: Enumerating objects: 1, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1)\u001b[K\rremote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "Receiving objects:   0% (1/108)   \rReceiving objects:   1% (2/108)   \rReceiving objects:   2% (3/108)   \rReceiving objects:   3% (4/108)   \rReceiving objects:   4% (5/108)   \rReceiving objects:   5% (6/108)   \rReceiving objects:   6% (7/108)   \rReceiving objects:   7% (8/108)   \rReceiving objects:   8% (9/108)   \rReceiving objects:   9% (10/108)   \rReceiving objects:  10% (11/108)   \rReceiving objects:  11% (12/108)   \rReceiving objects:  12% (13/108)   \rReceiving objects:  13% (15/108)   \rReceiving objects:  14% (16/108)   \rReceiving objects:  15% (17/108)   \rReceiving objects:  16% (18/108)   \rReceiving objects:  17% (19/108)   \rReceiving objects:  18% (20/108)   \rReceiving objects:  19% (21/108)   \rReceiving objects:  20% (22/108)   \rReceiving objects:  21% (23/108)   \rReceiving objects:  22% (24/108)   \rReceiving objects:  23% (25/108)   \rReceiving objects:  24% (26/108)   \rReceiving objects:  25% (27/108)   \rReceiving objects:  26% (29/108)   \rReceiving objects:  27% (30/108)   \rremote: Total 108 (delta 0), reused 0 (delta 0), pack-reused 107\n",
            "Receiving objects:  28% (31/108)   \rReceiving objects:  29% (32/108)   \rReceiving objects:  30% (33/108)   \rReceiving objects:  31% (34/108)   \rReceiving objects:  32% (35/108)   \rReceiving objects:  33% (36/108)   \rReceiving objects:  34% (37/108)   \rReceiving objects:  35% (38/108)   \rReceiving objects:  36% (39/108)   \rReceiving objects:  37% (40/108)   \rReceiving objects:  38% (42/108)   \rReceiving objects:  39% (43/108)   \rReceiving objects:  40% (44/108)   \rReceiving objects:  41% (45/108)   \rReceiving objects:  42% (46/108)   \rReceiving objects:  43% (47/108)   \rReceiving objects:  44% (48/108)   \rReceiving objects:  45% (49/108)   \rReceiving objects:  46% (50/108)   \rReceiving objects:  47% (51/108)   \rReceiving objects:  48% (52/108)   \rReceiving objects:  49% (53/108)   \rReceiving objects:  50% (54/108)   \rReceiving objects:  51% (56/108)   \rReceiving objects:  52% (57/108)   \rReceiving objects:  53% (58/108)   \rReceiving objects:  54% (59/108)   \rReceiving objects:  55% (60/108)   \rReceiving objects:  56% (61/108)   \rReceiving objects:  57% (62/108)   \rReceiving objects:  58% (63/108)   \rReceiving objects:  59% (64/108)   \rReceiving objects:  60% (65/108)   \rReceiving objects:  61% (66/108)   \rReceiving objects:  62% (67/108)   \rReceiving objects:  63% (69/108)   \rReceiving objects:  64% (70/108)   \rReceiving objects:  65% (71/108)   \rReceiving objects:  66% (72/108)   \rReceiving objects:  67% (73/108)   \rReceiving objects:  68% (74/108)   \rReceiving objects:  69% (75/108)   \rReceiving objects:  70% (76/108)   \rReceiving objects:  71% (77/108)   \rReceiving objects:  72% (78/108)   \rReceiving objects:  73% (79/108)   \rReceiving objects:  74% (80/108)   \rReceiving objects:  75% (81/108)   \rReceiving objects:  76% (83/108)   \rReceiving objects:  77% (84/108)   \rReceiving objects:  78% (85/108)   \rReceiving objects:  79% (86/108)   \rReceiving objects:  80% (87/108)   \rReceiving objects:  81% (88/108)   \rReceiving objects:  82% (89/108)   \rReceiving objects:  83% (90/108)   \rReceiving objects:  84% (91/108)   \rReceiving objects:  85% (92/108)   \rReceiving objects:  86% (93/108)   \rReceiving objects:  87% (94/108)   \rReceiving objects:  88% (96/108)   \rReceiving objects:  89% (97/108)   \rReceiving objects:  90% (98/108)   \rReceiving objects:  91% (99/108)   \rReceiving objects:  92% (100/108)   \rReceiving objects:  93% (101/108)   \rReceiving objects:  94% (102/108)   \rReceiving objects:  95% (103/108)   \rReceiving objects:  96% (104/108)   \rReceiving objects:  97% (105/108)   \rReceiving objects:  98% (106/108)   \rReceiving objects:  99% (107/108)   \rReceiving objects: 100% (108/108)   \rReceiving objects: 100% (108/108), 20.64 KiB | 4.13 MiB/s, done.\n",
            "Resolving deltas:   0% (0/47)   \rResolving deltas:  12% (6/47)   \rResolving deltas:  29% (14/47)   \rResolving deltas:  34% (16/47)   \rResolving deltas:  36% (17/47)   \rResolving deltas:  38% (18/47)   \rResolving deltas:  63% (30/47)   \rResolving deltas:  65% (31/47)   \rResolving deltas:  82% (39/47)   \rResolving deltas:  85% (40/47)   \rResolving deltas: 100% (47/47)   \rResolving deltas: 100% (47/47), done.\n",
            "Processing ./torch-dct\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from torch-dct==0.1.5) (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->torch-dct==0.1.5) (1.17.4)\n",
            "Building wheels for collected packages: torch-dct\n",
            "  Building wheel for torch-dct (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-dct: filename=torch_dct-0.1.5-cp36-none-any.whl size=4997 sha256=b43d2164a29af5e8408bb2b9e33e8d891a4a3cf56640702b241fcba1d8cf44d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/af/7d/bfc942607a03ab314a2c757dae2f27d25d9698e9ed106890ed\n",
            "Successfully built torch-dct\n",
            "Installing collected packages: torch-dct\n",
            "Successfully installed torch-dct-0.1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa-sLz0rkOyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!git clone https://github.com/tsakailab/spmlib\n",
        "#!pip install ./spmlib/."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "due82XR-a5mP",
        "colab_type": "code",
        "outputId": "6e01c80a-de47-4ea3-a65f-19749a8c0370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import torch\n",
        "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.3.1\n",
            "True\n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VTbHAYpOJV1",
        "colab_type": "code",
        "outputId": "9a2b2485-c768-4da9-8f89-2e6cb9200324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import torch_dct as tdct\n",
        "from pytorch_wavelets import DWTForward, DWTInverse\n",
        "import torch\n",
        "\n",
        "class uISTA(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, num_unroll, l=3., scale=1., prox=None, wt=None, iwt=None):\n",
        "        super(uISTA, self).__init__()\n",
        "        self.num_unroll = num_unroll #unroll回数\n",
        "        #self.A = torch.nn.Parameter(torch.FloatTensor(A), requires_grad=True)#fhみたいなのに変更する\n",
        "        self.l = torch.nn.Parameter(torch.FloatTensor([l]), requires_grad=True)#なんか配列作ってる多分なんかの計算用theta\n",
        "        self.scale = scale#thetaの計算に使ってる\n",
        "        print(device)\n",
        "        if prox is None:\n",
        "            #self.prox = lambda z, th: torch.max((z.sign() * (z.abs_() - th)),torch.tensor([0]).float())\n",
        "            self.prox = lambda z, th: z.sign() * (z.abs_() - th).max(torch.tensor(0, device=device).float())\n",
        "            #zの値を0か負(=-1)か正(=1)か判定したやつとsoft閾値処理したやつの乗算\n",
        "        else:\n",
        "            self.prox = prox\n",
        "\n",
        "        if wt is None:\n",
        "            self.wt = DWTForward(J=3,wave='db10',mode='zero')\n",
        "        else:\n",
        "            self.wt = wt\n",
        "\n",
        "        if iwt is None:\n",
        "            self.iwt = DWTInverse(wave='db10', mode='zero')\n",
        "        else:\n",
        "            self.iwt = iwt\n",
        "\n",
        "    def forward(self, b):\n",
        "        theta = torch.mul(self.l, self.scale)#lの要素をscale倍するらしい\n",
        "        # prox(A.dot(b*scale), theta) for initial guess of x xの初期値を決めるよ\n",
        "        #x = self.prox(b.mul(self.scale).matmul(self.A), theta)    #matmulをidctにidwtに\n",
        "        x = self.prox(self.tidct(b.mul_(self.scale)), theta)\n",
        "        print(x[0])\n",
        "        plt.plot(torch.arange(0,len(x[0])).cpu(),x[0].cpu().detach().numpy())\n",
        "        print(1111111)\n",
        "        #coeffs = self.dwt(b.reshape(1,1,1,-1))\n",
        "        #w = self.w_softshrink(self.idwt(self.idwt(self.dwt(b.reshape(1,1,1,-1)))), theta)\n",
        "        #w = torch.zeros(1,1,1,len(b[0]))\n",
        "        w = b\n",
        "        #print(x.size(),w.size())\n",
        "        for i in range(self.num_unroll):\n",
        "            #x = prox(x+A.T.dot(b-A.dot(x))*scale, theta) ISTAの繰り返し部分\n",
        "            #x = soft(x + AT(b - Ax))scale\n",
        "            #x = self.prox(x + (b - x.matmul(self.A.t())).mul_(self.scale).matmul(self.A), theta)\n",
        "            #matmul A.t をdct,dwtに matmul Aをidct,idwtに\n",
        "            x = self.prox(x + (b - self.tidct(self.tdct(x).mul_(self.scale))), theta) \n",
        "            print(i)\n",
        "            #w = self.w_softshrink(w + (b.reshape(-1,1,1,b.size()[0]) - self.idwt(dwt(w).mul_(self.scale))), theta)\n",
        "            #w = self.w_softshrink(w + (b.reshape(1,1,1,-1) - self.idwt([[j.mul_(self.scale) for j in i[1]] for i in self.dwt(w)])), theta)\n",
        "            test = self.dwt(w)\n",
        "            print('after f')\n",
        "            #w = self.w_softshrink(w + (b.reshape(1,1,1,-1) - self.idwt((self.dwt(w)[0].mul_(self.scale),[i.mul_(self.scale)for i in self.dwt(w)[1]]))), theta) \n",
        "            w = self.w_softshrink(w + (b.reshape(1,1,1,-1) - self.idwt((test[0].mul_(self.scale),[i.mul_(self.scale)for i in test[1]]))), theta) \n",
        "        return x,w\n",
        "\n",
        "    #関数AとATのかわり\n",
        "    def tdct(self,x):\n",
        "        return tdct.dct(x)\n",
        "    \n",
        "    def tidct(self,x):\n",
        "        return tdct.idct(x)\n",
        "\n",
        "    def dwt(self,x):\n",
        "        return self.wt(x)\n",
        "\n",
        "    def idwt(self,x):\n",
        "        return self.iwt((x[0],x[1]))\n",
        "\n",
        "    def w_softshrink(self,z,th):\n",
        "        return [self.prox(x,th) for x in z]\n",
        "\"\"\"\n",
        "    #%% sign function compatible with complex values\n",
        "    def sgn(z):\n",
        "        return torch.div(z, z.abs())\n",
        "\n",
        "    #%% soft thresholding function compatible with complex values\n",
        "    def f_softshrink(z, th):\n",
        "        return sgn(z) * torch.max(z.abs() - th, torch.tensor([0]).float())\n",
        "        \"\"\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    #%% sign function compatible with complex values\\n    def sgn(z):\\n        return torch.div(z, z.abs())\\n\\n    #%% soft thresholding function compatible with complex values\\n    def f_softshrink(z, th):\\n        return sgn(z) * torch.max(z.abs() - th, torch.tensor([0]).float())\\n        '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv4UEoWi0HO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "softm = lambda z, th: z.sign() * torch.max(z.abs() - th, torch.tensor([0]).float())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPHcnbTXwGyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sgn(z):\n",
        "    return torch.div(z, z.abs())\n",
        "\n",
        "#%% soft thresholding function compatible with complex values\n",
        "def f_softshrink(z, th):\n",
        "    return sgn(z) * torch.max(z.abs() - th, torch.tensor([0]).float())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdY985eXxABI",
        "colab_type": "code",
        "outputId": "1404d276-6368-4080-ed0b-a5c993dcf601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "\n",
        "rng = np.random.RandomState(int(time()))\n",
        "\n",
        "n_samples = 200\n",
        "#m, n = 512, 2048\n",
        "m, n = 256,1024\n",
        "#m, n = 2000, 4000\n",
        "\n",
        "# generate k-sparse Gaussian signal vectors\n",
        "k = 50\n",
        "stdx = 1.\n",
        "snr = 10.\n",
        "support_range = np.arange(0, n)\n",
        "data = torch.arange(0, 10, 0.00005)\n",
        "print(data.size())\n",
        "frequency = torch.arange(0.02,2,0.02)\n",
        "g = torch.rand(frequency.size()[0])\n",
        "y = torch.zeros((n_samples,data.size()[0]))\n",
        "\n",
        "input_data = torch.zeros((n_samples, data.size()[0]))\n",
        "print(input_data.size()[1])\n",
        "true = torch.zeros((n_samples, data.size()[0]))\n",
        "output_data = torch.zeros((n_samples, n))\n",
        "G = rng.choice(198000,500,replace=False)\n",
        "for sample in range(n_samples) :\n",
        "    T = rng.choice(frequency.size()[0], 20, replace=False)\n",
        "\n",
        "    for i in range(0,20):\n",
        "        y[sample] = y[sample] + g[T[i]] * torch.cos(2 * math.pi * (1. /frequency[T[i]]) * data) \n",
        "    #y[sample] = y[sample] / y[sample].max()\n",
        "    y_add_noise = y[sample] + torch.rand(data.size())\n",
        "    for i in range(0,50):\n",
        "        y_add_noise[G[i]+10] = y_add_noise[G[i]+10] + 3\n",
        "\n",
        "    '''\n",
        "    # add noise\n",
        "    normb = linalg.norm(b)\n",
        "    noise = rng.randn(m)\n",
        "    noise = noise / linalg.norm(noise) * normb / snr\n",
        "    b = b + noise\n",
        "    '''\n",
        "\n",
        "    input_data[sample, :] = y_add_noise\n",
        "    true[sample, :] = y[sample]\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([200000])\n",
            "200000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUy4R7lBdUYB",
        "colab_type": "code",
        "outputId": "b40bf106-6d7d-4b50-942f-4bf89233e16f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "input_data.to(device=device)\n",
        "print(input_data.size())\n",
        "true"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([200, 200000])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 9.8638,  9.8637,  9.8636,  ..., -2.5147, -2.5118, -2.5088],\n",
              "        [10.0690, 10.0690, 10.0690,  ...,  1.8500,  1.8490,  1.8479],\n",
              "        [12.7361, 12.7361, 12.7361,  ..., -1.0188, -1.0182, -1.0175],\n",
              "        ...,\n",
              "        [ 9.8601,  9.8601,  9.8601,  ...,  0.0358,  0.0349,  0.0340],\n",
              "        [ 9.4711,  9.4710,  9.4710,  ..., -2.5606, -2.5591, -2.5576],\n",
              "        [10.7865, 10.7865, 10.7864,  ...,  2.6395,  2.6386,  2.6377]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRIS8wBGeIZ4",
        "colab_type": "code",
        "outputId": "126dd167-3e80-4c6e-907c-8f7aef1f21aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model = uISTA(5).to(device=device)\n",
        "model.cuda()\n",
        "print(model.named_parameters())\n",
        "print(model.parameters())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "<generator object Module.named_parameters at 0x7f27c01662b0>\n",
            "<generator object Module.parameters at 0x7f27c01662b0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO8c874X5fYp",
        "colab_type": "code",
        "outputId": "7071a4f7-8fc0-4d77-c67e-18ba78a35a56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print('Is model parameters on GPU? :', next(model.parameters()).is_cuda)\n",
        "for param in model.parameters():\n",
        "    print(type(param.data), param.size(), ', is_cuda:', param.is_cuda)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is model parameters on GPU? : True\n",
            "<class 'torch.Tensor'> torch.Size([1]) , is_cuda: True\n",
            "<class 'torch.Tensor'> torch.Size([1, 1, 20, 1]) , is_cuda: True\n",
            "<class 'torch.Tensor'> torch.Size([1, 1, 20, 1]) , is_cuda: True\n",
            "<class 'torch.Tensor'> torch.Size([1, 1, 1, 20]) , is_cuda: True\n",
            "<class 'torch.Tensor'> torch.Size([1, 1, 1, 20]) , is_cuda: True\n",
            "<class 'torch.Tensor'> torch.Size([1, 1, 20, 1]) , is_cuda: True\n",
            "<class 'torch.Tensor'> torch.Size([1, 1, 20, 1]) , is_cuda: True\n",
            "<class 'torch.Tensor'> torch.Size([1, 1, 1, 20]) , is_cuda: True\n",
            "<class 'torch.Tensor'> torch.Size([1, 1, 1, 20]) , is_cuda: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdNnG5JGfJcL",
        "colab_type": "code",
        "outputId": "4ff8e6d9-417b-44a8-846b-142110dbebcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        }
      },
      "source": [
        "model_out = model.forward(input_data)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., -0., 0.,  ..., 0., -0., -0.], grad_fn=<SelectBackward>)\n",
            "1111111\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-e014b3fd954b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-abe8aea8d739>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m#w = self.w_softshrink(w + (b.reshape(-1,1,1,b.size()[0]) - self.idwt(dwt(w).mul_(self.scale))), theta)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m#w = self.w_softshrink(w + (b.reshape(1,1,1,-1) - self.idwt([[j.mul_(self.scale) for j in i[1]] for i in self.dwt(w)])), theta)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdwt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m#w = self.w_softshrink(w + (b.reshape(1,1,1,-1) - self.idwt((self.dwt(w)[0].mul_(self.scale),[i.mul_(self.scale)for i in self.dwt(w)[1]]))), theta)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-abe8aea8d739>\u001b[0m in \u001b[0;36mdwt\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdwt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0midwt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_wavelets/dwt/transform2d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# Do 1 level of the transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             ll, high = lowlevel.AFB2D.apply(\n\u001b[0;32m---> 72\u001b[0;31m                 ll, self.h0_col, self.h1_col, self.h0_row, self.h1_row, mode)\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0myh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_wavelets/dwt/lowlevel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, x, h0_row, h1_row, h0_col, h1_col, mode)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint_to_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mlohi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafb1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh1_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafb1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlohi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh1_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_wavelets/dwt/lowlevel.py\u001b[0m in \u001b[0;36mafb1d\u001b[0;34m(x, h0, h1, mode, dim)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m     \u001b[0;31m# If h0, h1 are not tensors, make them. If they are, then assume that they\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;31m# are in the right order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD4CAYAAADo30HgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH2s1LNFK5is5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybJ4yyU9tfWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j = 198\n",
        "print(\"xの結果\\n\",model_out[0])\n",
        "print(\"xとフーリエ変換したものの乗算\\n\",tdct.dct(input_data[j]).mul(model_out[0][j]))\n",
        "print(\"スパース解xをつかって求めた波形\\n\",tdct.idct(tdct.dct(input_data[j]).mul(model_out[0][j]).div(model_out[0][j].max())))\n",
        "check = tdct.idct(tdct.dct(input_data[j]).mul(model_out[0][j]).div(model_out[0][j].max()))\n",
        "print(type(check))\n",
        "plt.subplot(5,1,1)\n",
        "plt.plot(data.cpu(),true[j].cpu())\n",
        "plt.subplot(5,1,2)\n",
        "plt.plot(data.cpu(),y_add_noise.cpu().detach().numpy())\n",
        "plt.subplot(5,1,3)\n",
        "plt.plot(data.cpu(),check.cpu().detach().numpy())\n",
        "plt.subplot(5,1,4)\n",
        "plt.plot(data.cpu(),tdct.dct(input_data[j]).mul(model_out[0][j]).cpu().detach().numpy())\n",
        "plt.subplot(5,1,5)\n",
        "plt.plot(torch.arange(0,len(data)).cpu(),model_out[0][j].cpu().detach().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPPT2E-8uB-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wt = DWTForward(J=3,wave='db10',mode='zero')\n",
        "iwt = DWTInverse(wave='db10', mode='zero')\n",
        "\n",
        "j = 198\n",
        "print(\"wの結果\\n\",model_out[1])\n",
        "#print(\"wとフーリエ変換したものの乗算\\n\",tdct.dct(input_data[j]).mul(model_out[1][j]))\n",
        "print(\"スパース解wをつかって求めた波形\\n\",iwt(wt(input_data[j]).mul(model_out[1][j]).div(model_out[1][j].max())))\n",
        "check = tdct.idct(tdct.dct(input_data[j]).mul(model_out[1][j]).div(model_out[1][j].max()))\n",
        "print(type(check))\n",
        "plt.subplot(5,1,1)\n",
        "plt.plot(data.cpu(),true[j].cpu())\n",
        "plt.subplot(5,1,2)\n",
        "plt.plot(data.cpu(),y_add_noise.cpu().detach().numpy())\n",
        "plt.subplot(5,1,3)\n",
        "plt.plot(data.cpu(),check.cpu().detach().numpy())\n",
        "plt.subplot(5,1,4)\n",
        "plt.plot(data.cpu(),tdct.dct(input_data[j]).mul(model_out[1][j]).cpu().detach().numpy())\n",
        "plt.subplot(5,1,5)\n",
        "plt.plot(torch.arange(0,len(data)).cpu(),model_out[1][j].cpu().detach().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggl3qZQIyxV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def w_softshrink(self,z,th):\n",
        "    return [self.prox(x,th) for x in z]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQp3NXVuaLTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "import torch\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "#import torch_dct as tdct\n",
        "torch.set_default_tensor_type(torch.FloatTensor)\n",
        "\n",
        "#b * cos(2 * pi * (1/x)) #(1/x) = f\n",
        "a = torch.arange(0, 10, 0.0005)\n",
        "b = torch.rand(20)\n",
        "x = torch.arange(0.2,20,0.2)\n",
        "y = 0\n",
        "for i in range(0,9):\n",
        "    y = y + b[i] * torch.cos(2 * math.pi * (1. /x[i]) * a) \n",
        "y[600] = y[600] + 2\n",
        "y_add_noise = y + torch.rand(20000)\n",
        "print(y)\n",
        "print(y.size())\n",
        "plt.subplot(4,1,1)\n",
        "plt.plot(a,y)\n",
        "plt.subplot(4,1,2)\n",
        "plt.plot(a,y_add_noise)\n",
        "dcty = tdct.dct(y_add_noise)\n",
        "idcty = tdct.idct(dcty)\n",
        "idcty = tdct.idct(softm(dcty,0))\n",
        "plt.plot(a,idcty)\n",
        "yfft = torch.rfft(y_add_noise,1)\n",
        "print(yfft)\n",
        "yfft = f_softshrink(yfft,100)\n",
        "print(yfft)\n",
        "yifft = torch.irfft(yfft,1,signal_sizes = y.shape)\n",
        "print(yifft)\n",
        "plt.subplot(4,1,3)\n",
        "plt.plot(a,yifft)\n",
        "plt.subplot(4,1,4)\n",
        "#plt.plot(a,dcty)\n",
        "plt.plot(torch.arange(19940),dcty[60:])\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1PTSJ2ih7BZV",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "import torch\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from pytorch_wavelets import DWTForward, DWTInverse\n",
        "import torch_dct as tdct\n",
        "\n",
        "maxnum = 10\n",
        "#b * cos(2 * pi * (1/x)) #(1/x) = f\n",
        "a = torch.arange(0, 10, 0.0005)\n",
        "b = torch.rand(maxnum)\n",
        "x = torch.arange(0.2,maxnum,0.2)\n",
        "y = 0\n",
        "for i in range(0,maxnum):\n",
        "    y = y + b[i] * torch.cos(2 * math.pi * (1. /x[i]) * a) \n",
        "y[600] = y[600] + 5\n",
        "y_add_noise = y + torch.rand(20000)\n",
        "print(y)\n",
        "print(y.size())\n",
        "plt.subplot(5,1,1)\n",
        "plt.plot(a,y)\n",
        "plt.subplot(5,1,2)\n",
        "plt.plot(a,y_add_noise)\n",
        "\n",
        "wty = DWTForward(J=3, wave=\"db10\", mode='zero')\n",
        "iwty = DWTInverse(wave=\"db10\", mode='zero')\n",
        "Yl, Yh = wty(y_add_noise.view(1,1,1,y.size()[0]))\n",
        "Yh = [softm(x,100) for x in Yh]\n",
        "iwtyy = iwty((Yl,Yh))\n",
        "print(iwtyy)\n",
        "plt.subplot(5,1,3)\n",
        "plt.plot(a,iwtyy[0][0][0])\n",
        "\n",
        "dcty = tdct.dct(y_add_noise)\n",
        "dcty = softm(dcty,200)\n",
        "idcty = tdct.idct(dcty)\n",
        "plt.subplot(5,1,4)\n",
        "plt.plot(a,idcty)\n",
        "print(idcty)\n",
        "\n",
        "yfft = torch.rfft(y_add_noise,1)\n",
        "yfft = f_softshrink(yfft,200)\n",
        "yifft = torch.irfft(yfft,1,signal_sizes = y.shape)\n",
        "print(yifft)\n",
        "plt.subplot(5,1,5)\n",
        "plt.plot(a,yifft)\n",
        "\n",
        "print(torch.abs((y - idcty).sum()))\n",
        "print(torch.abs((y - yifft).sum()))\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i0SpAxxxCB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import fftpack\n",
        "\n",
        "#b * cos(2 * pi * (1/x)) #(1/x) = f\n",
        "a = np.arange(0, 10, 0.0005)\n",
        "b = np.random.rand(9)\n",
        "x = np.arange(0.02,2,0.05)\n",
        "y = np.zeros(len(a))\n",
        "for i in range(0,9):\n",
        "    y = y + b[i] * np.cos(2 * math.pi * (1. /x[i]) * a) \n",
        "print(y)\n",
        "y = y #+ np.random.rand(len(y)) * 3\n",
        "print(len(y))\n",
        "print(x.size)\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(a,y)\n",
        "\n",
        "ydct = fftpack.dct(y,norm='ortho')\n",
        "yidct = fftpack.idct(ydct,norm='ortho')\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(a,yidct)\n",
        "print(y)\n",
        "print(ydct)\n",
        "print(yidct)\n",
        "print(y - yidct)\n",
        "print((np.fabs(y - yidct)).sum())\n",
        "assert (y - yidct).sum() < 1e-10\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}